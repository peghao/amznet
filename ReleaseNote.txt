Release Note：

2022-07-16
1. 解决了test_mnist.c计算结果和pytorch不一致的问题。该问题由以下两个原因导致：1反向传播流程控制·问题，修改了递归停止的条件 2全连接层bias张量不应该使用add_broad函数相加，为此新增了add_distri函数
2. 在matrix.h中新增了一个matrix_constant函数

2022-07-24
1. 为tensor添加了release函数，可以释放计算图
2. 更新了test_mnist.c，可以通过正向-反向的循环训练网络参数，实现loss值下降
遇到的问题：
1. 如何区分计算图的输入tensor和计算中临时创建的tensor？因为两者的requires_grad属性都是false
解决方案：把临时tensor的op设为UNKNOW或CONST来区分
2. 递归释放计算图时可能会对同一个tensor double free，如何避免？
解决方案：不用递归地遍历计算图，将计算图中的所有tensor添加到一个链表中，然后遍历链表逐一释放计算图中的节点

2022-07-26
1. 调整了项目结构，为项目增加了Makefile
2. 把tensor.h编译成动态链接库

2022-07-28
1. 实现了model类，搭建自己的神经网络时可以继承这个类
2. 开发中引入了c++语言
3. 重写了项目计划

2022-07-29
1. 优化计算速度（在Intel Core i7-7500U上）：
速度测试：MNIST数据集，batchsize=128，训练步数10步
无优化：566.67秒
优化sum_all反向过程：无明显变化
优化矩阵乘法反向过程：1.9秒

2022-08-06
1. 实现了一个带动量的SGD优化器，可以将MNIST训练集上的loss降到10e-2数量级
遇到的问题：
1. 测试优化器代码时无论如何训练都不收敛
解决方案：导致训练不收敛的主要原因是输入图像未归一化，添加归一化之后就可以了